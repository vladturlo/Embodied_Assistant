# Ollama Model Configuration
# Used by the multimodal agent for vision and text processing
#
# Available models:
#   - qwen3-vl:2b     (local, fits on 4GB VRAM)
#   - qwen3-vl:32b    (remote, balanced speed/quality)
#   - qwen3-vl:235b   (remote, highest quality, slow)
#   - ministral-3:14b (remote, fast, check vision support)

provider: ollama
model: ministral-3:14b
host: http://localhost:11435

# Model capabilities
capabilities:
  vision: true
  function_calling: true
  json_output: false
  structured_output: false

# Generation options
options:
  temperature: 0.7
  num_ctx: 8192  # 8K context for faster inference

# Model info for AutoGen
model_info:
  vision: true
  function_calling: true
  json_output: false
  family: unknown
  structured_output: false

# Video processing settings
video:
  frames_per_second: 5.0  # Frames to extract per second of video
  max_frames: 50          # Maximum frames to prevent overload on long videos

# Image capture settings for embodied control
# Lower resolution = faster model inference
image:
  max_width: 640      # Maximum image width
  max_height: 480     # Maximum image height
  jpeg_quality: 70    # JPEG compression quality (0-100)
