# Model Configuration
# Supports multiple providers:
#   - ollama: Direct Ollama API (single instance)
#   - litellm: LiteLLM proxy (load-balanced multi-GPU)
#   - llamacpp: llama.cpp OpenAI-compatible server
#
# For llama.cpp server, start with:
#   llama-server -m model.gguf --mmproj mmproj.gguf -c 262144 -np 1 --host 0.0.0.0 --port 11434 -sps 0.0

provider: litellm

# Model name (must match LiteLLM model_name or llama-server model)
model: ministral-3

# LiteLLM proxy endpoint (load-balanced across 4 GPUs)
# SSH tunnel: ssh -A -N -L 11400:localhost:11400 <node>
base_url: http://localhost:11400/v1
api_key: not-needed

# Model capabilities
capabilities:
  vision: true
  function_calling: true
  json_output: false
  structured_output: false

# Generation options
options:
  temperature: 0.15  # Low temperature as recommended by Mistral
  num_ctx: 262144  # 256K full context

# llama.cpp specific options for KV cache persistence
# These are passed via extra_body in the OpenAI request
# (only used when provider: llamacpp)
# llamacpp:
#   id_slot: 0           # Dedicated slot for embodied mode (KV cache affinity)
#   cache_prompt: true   # Enable KV cache reuse for matching prefixes

# Model info for AutoGen
model_info:
  vision: true
  function_calling: true
  json_output: false
  family: mistral
  structured_output: false

# Video processing settings
video:
  frames_per_second: 5.0  # Frames to extract per second of video
  max_frames: 50          # Maximum frames to prevent overload on long videos

# Image capture settings for embodied control
# Lower resolution = faster model inference + fewer visual tokens
image:
  max_width: 480      # Maximum image width (reduced from 640 for speed)
  max_height: 360     # Maximum image height (reduced from 480 for speed)
  jpeg_quality: 65    # JPEG compression quality (0-100)

# Pipeline settings for embodied control
# 4 GPUs x OLLAMA_NUM_PARALLEL=2 = 8 concurrent slots
pipeline:
  enabled: false        # Set to true after confirming multi-GPU setup
  slots: 8              # 4 GPUs Ã— 2 parallel each
  move_distance: 15     # Pixels per move (smaller = smoother at ~48ms intervals)
  smooth_movement: true # Continuous cursor movement with direction averaging
  speed_px_per_sec: 200 # Cursor speed in pixels per second (only when smooth_movement=true)
